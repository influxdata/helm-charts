# ============================================================================
# Global Configuration
# ============================================================================

# Cluster configuration - all nodes must share the same cluster ID
cluster:
  # Unique identifier for the cluster (must be different from any node-id)
  id: "cluster-01"

  # Cluster management settings for multi-node coordination
  replicationInterval: "250ms"      # Data replication interval between nodes
  catalogSyncInterval: "10s"        # Catalog synchronization interval
  waitForRunningIngestor: "10s"    # Startup wait time for ingestor

# Naming overrides
nameOverride: ""
fullnameOverride: ""

# Image configuration
image:
  registry: docker.io
  repository: influxdb
  tag: "3-enterprise"
  pullPolicy: IfNotPresent

imagePullSecrets: []
# - name: registry-secret

# ============================================================================
# Object Storage Configuration
# ============================================================================
# InfluxDB 3 Enterprise requires object storage for persisting Parquet files.
# All nodes in the cluster must connect to the same object store.

objectStorage:
  # Object store type: s3, azure, google, file, memory, memory-throttled
  # Default: s3 (recommended for production)
  type: s3

  # Bucket/container name for storing data
  bucket: "influxdb3-enterprise-data"

  # Connection settings
  connectionLimit: 16               # Max connections to object store
  http2Only: false                  # Force HTTP/2 connections
  maxRetries: null                  # Max retry attempts (null = default)
  retryTimeout: null                # Max retry duration (null = default)

  # S3 and S3-compatible storage (MinIO, etc.)
  s3:
    enabled: true
    # AWS region (required for AWS S3)
    region: "us-east-1"
    # S3 endpoint URL (leave empty for AWS, set for S3-compatible like MinIO)
    # Examples:
    #   AWS: "" (uses default regional endpoint)
    #   MinIO: "http://minio.minio.svc.cluster.local:9000"
    endpoint: ""
    # Access credentials
    accessKeyId: ""
    secretAccessKey: ""
    sessionToken: ""                # Optional, for federated/SSO
    # Connection options
    allowHttp: false                # Set true for HTTP (non-TLS) connections
    skipSignature: false            # Skip request signing (not recommended)
    # Credentials file (alternative to accessKeyId/secretAccessKey)
    credentialsFile: ""             # Path to JSON credentials file

    # Existing secret (alternative to specifying credentials here)
    # If specified, the chart will use this secret instead of creating one
    # Secret should contain keys: access-key-id, secret-access-key
    existingSecret: ""

  # Azure Blob Storage
  # Uncomment to use Azure instead of S3
  azure:
    enabled: false
  #   storageAccount: ""
  #   accessKey: ""
  #   endpoint: ""                  # Optional, Azure Blob Storage endpoint
  #   allowHttp: false
  #   # Existing secret (alternative)
  #   existingSecret: ""

  # Google Cloud Storage
  # Uncomment to use GCS instead of S3
  google:
    enabled: false
  #   # Service account JSON content or path
  #   serviceAccountJson: ""
  #   # Or provide as existing secret
  #   existingSecret: ""
  #   secretKey: "service-account.json"

  # Local filesystem (for development/testing only)
  # NOT RECOMMENDED for production - use cloud object storage
  # Uncomment to use local filesystem for quick testing:
  # file:
  #   enabled: false
  #   dataDir: "/var/lib/influxdb3"
  #   # Persistent volume for file storage
  #   persistence:
  #     enabled: true
  #     storageClass: ""
  #     size: 100Gi

  # In-memory storage (for testing only, no persistence)
  # memory:
  #   enabled: false
  #   throttled: false              # Set true to simulate cloud latency

# ============================================================================
# License Configuration
# ============================================================================
# InfluxDB 3 Enterprise requires a license. Three types available:
# - trial: 30-day trial with full features
# - home: For at-home hobbyist use (limited to 2 cores)
# - commercial: Full commercial license

license:
  # License type: trial, home, or commercial
  type: "trial"

  # Email address for trial/home licenses
  # Required for trial and home licenses
  email: ""

  # License file path (for commercial licenses)
  # Mutually exclusive with email
  file: ""

  # Existing secret containing license information
  # If specified, email and file are ignored
  # Secret should contain key: license-email or license-file
  existingSecret: ""

# ============================================================================
# Probes Configuration (Shared across all components)
# ============================================================================
# Note: /health endpoint authentication is disabled by default (auth.disableAuthz: ["health"])
# so probes work without requiring tokens
probes:
  # Enable or disable health probes globally
  enabled: true

  # Startup probe settings
  # Protects container during initialization. Once successful, never runs again.
  # For ~15s startup: 10s initial + (12 × 5s) = 70s total (4-5x safety buffer)
  startup:
    initialDelaySeconds: 10           # Wait ~50% of expected startup time
    periodSeconds: 5                  # Check every 5 seconds
    timeoutSeconds: 5
    failureThreshold: 12              # 10s + (12 × 5s) = 70s total

  # Liveness probe settings
  # Only starts checking AFTER startup probe succeeds
  liveness:
    initialDelaySeconds: 0            # No delay needed - startup probe protects
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 3               # 3 × 10s = 30s before restart

  # Readiness probe settings
  # Only starts checking AFTER startup probe succeeds
  readiness:
    initialDelaySeconds: 0            # No delay needed - startup probe protects
    periodSeconds: 5                  # Check frequently
    timeoutSeconds: 3
    failureThreshold: 3

# ============================================================================
# Component Deployment Configuration
# ============================================================================
# InfluxDB 3 Enterprise supports specialized nodes for different workloads.
# Each component can be scaled independently based on your requirements.

# Ingester nodes - Handle data writes
ingester:
  enabled: true
  replicas: 2                       # Number of ingester nodes

  # Resource allocation
  resources:
    requests:
      cpu: "2000m"                  # 2 cores
      memory: "4Gi"
    limits:
      cpu: "4000m"                  # 4 cores max
      memory: "8Gi"

  # Thread configuration for ingest workload
  threads:
    io: 8                           # For line protocol parsing
    datafusion: 16                  # For WAL snapshots
    memPoolBytes: "60%"             # Memory pool allocation

  # Persistent storage for Write-Ahead Log (WAL)
  persistence:
    enabled: true
    storageClass: ""                # Use default storage class
    size: "10Gi"                    # Minimum 2Gi recommended
    accessMode: ReadWriteOnce

  # Pod affinity/anti-affinity, node selectors, tolerations
  # Default: soft anti-affinity to spread pods across nodes when possible
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: ingester
            topologyKey: kubernetes.io/hostname
  nodeSelector: {}
  tolerations: []

  # Additional pod annotations and labels
  podAnnotations: {}
  podLabels: {}

  # Security context
  # InfluxDB3 runs as uid=1500(influxdb3) gid=1500(influxdb3)
  podSecurityContext:
    fsGroup: 1500              # Ensures volumes are owned by influxdb3 group
    runAsNonRoot: true         # Security best practice
    runAsUser: 1500            # Run as influxdb3 user
    runAsGroup: 1500           # Run as influxdb3 group

  # Service configuration
  service:
    type: ClusterIP
    port: 8181
    annotations: {}

  # Pod disruption budget for high availability
  # Ensures minimum number of ingester pods remain available during voluntary disruptions
  podDisruptionBudget:
    enabled: false
    minAvailable: 1

  # Priority class for pod scheduling priority
  # Higher priority pods are scheduled before lower priority pods
  # Use "system-cluster-critical" or "system-node-critical" for critical workloads
  priorityClassName: ""

  # Update strategy for rolling updates
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0                  # Start updating from pod 0

# Querier nodes - Handle query requests
querier:
  enabled: true
  replicas: 2                       # Number of querier nodes

  # Resource allocation
  resources:
    requests:
      cpu: "2000m"
      memory: "4Gi"
    limits:
      cpu: "4000m"
      memory: "8Gi"

  # Thread configuration for query workload
  threads:
    io: 4                           # Minimal for HTTP requests
    datafusion: 20                  # Maximum for query processing
    memPoolBytes: "80%"             # More memory for aggregations

  # No persistent storage needed for queriers

  # Pod affinity/anti-affinity, node selectors, tolerations
  # Default: soft anti-affinity to spread pods across nodes when possible
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: querier
            topologyKey: kubernetes.io/hostname
  nodeSelector: {}
  tolerations: []

  # Additional pod annotations and labels
  podAnnotations: {}
  podLabels: {}

  # Security context
  # InfluxDB3 runs as uid=1500(influxdb3) gid=1500(influxdb3)
  podSecurityContext:
    fsGroup: 1500              # Ensures volumes are owned by influxdb3 group
    runAsNonRoot: true         # Security best practice
    runAsUser: 1500            # Run as influxdb3 user
    runAsGroup: 1500           # Run as influxdb3 group

  # Service configuration
  service:
    type: ClusterIP
    port: 8181
    annotations: {}

  # Pod disruption budget for high availability
  # Ensures minimum number of querier pods remain available during voluntary disruptions
  podDisruptionBudget:
    enabled: false
    minAvailable: 1

  # Priority class for pod scheduling priority
  # Higher priority pods are scheduled before lower priority pods
  # Use "system-cluster-critical" or "system-node-critical" for critical workloads
  priorityClassName: ""

  # Update strategy for rolling updates
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0                  # Start updating from pod 0

# Compactor node - Background data optimization (single node only)
compactor:
  enabled: true
  # IMPORTANT: Must be set to 1
  # InfluxDB3 Enterprise supports only ONE compactor per cluster
  # Multiple compactors will cause data corruption and conflicts
  # DO NOT change this value unless explicitly advised by InfluxData
  replicas: 1

  # Resource allocation (CPU-intensive)
  resources:
    requests:
      cpu: "2000m"
      memory: "2Gi"
    limits:
      cpu: "4000m"
      memory: "4Gi"

  # Thread configuration for compaction workload
  threads:
    io: 2                           # Minimal IO threads
    datafusion: 24                  # Maximum for sort/merge operations

  # Compaction settings
  compaction:
    gen1Duration: "10m"             # 1m, 5m, or 10m
    gen2Duration: "20m"
    multipliers: "3,4,6,5"          # Compaction level multipliers
    maxNumFilesPerPlan: 500
    cleanupWait: "10m"
    checkInterval: "10s"

  # No persistent storage needed for compactor

  # Pod affinity/anti-affinity, node selectors, tolerations
  affinity: {}
  nodeSelector: {}
  tolerations: []

  # Additional pod annotations and labels
  podAnnotations: {}
  podLabels: {}

  # Security context
  # InfluxDB3 runs as uid=1500(influxdb3) gid=1500(influxdb3)
  podSecurityContext:
    fsGroup: 1500              # Ensures volumes are owned by influxdb3 group
    runAsNonRoot: true         # Security best practice
    runAsUser: 1500            # Run as influxdb3 user
    runAsGroup: 1500           # Run as influxdb3 group

  # Service configuration (for metrics only)
  service:
    type: ClusterIP
    port: 8181
    annotations: {}

  # Priority class for pod scheduling priority
  # Higher priority pods are scheduled before lower priority pods
  # Use "system-cluster-critical" or "system-node-critical" for critical workloads
  priorityClassName: ""

  # Update strategy for rolling updates
  updateStrategy:
    type: RollingUpdate

# Processing Engine nodes - Custom data processing (optional)
processingEngine:
  enabled: false
  replicas: 1

  # Resource allocation
  resources:
    requests:
      cpu: "2000m"
      memory: "4Gi"
    limits:
      cpu: "4000m"
      memory: "8Gi"

  # Thread configuration
  threads:
    io: 4
    datafusion: 12

  # Plugin configuration
  pluginDir: "/plugins"
  pluginRepo: ""                    # Custom plugin repository URL (optional)
  packageManager: "discover"        # discover, pip, uv, or disabled

  # Persistent storage for plugins
  persistence:
    enabled: true
    storageClass: ""
    size: "5Gi"
    accessMode: ReadWriteOnce

  # Pre-install plugins via initContainer (optional)
  initPlugins: []
    # - name: system-metrics
  #   source: "gh:influxdata/system_metrics/system_metrics.py"

  # Pod affinity/anti-affinity, node selectors, tolerations
  # Default: soft anti-affinity to spread pods across nodes when possible
  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchLabels:
                app.kubernetes.io/component: processor
            topologyKey: kubernetes.io/hostname
  nodeSelector: {}
  tolerations: []

  # Additional pod annotations and labels
  podAnnotations: {}
  podLabels: {}

  # Security context
  # InfluxDB3 runs as uid=1500(influxdb3) gid=1500(influxdb3)
  podSecurityContext:
    fsGroup: 1500              # Ensures volumes are owned by influxdb3 group
    runAsNonRoot: true         # Security best practice
    runAsUser: 1500            # Run as influxdb3 user
    runAsGroup: 1500           # Run as influxdb3 group

  # Container-level security context (optional override)
  securityContext: {}

  # Service configuration
  service:
    type: ClusterIP
    port: 8181
    annotations: {}

  # Update strategy for rolling updates
  updateStrategy:
    type: RollingUpdate
    rollingUpdate:
      partition: 0                  # Start updating from pod 0

  # Pod disruption budget for high availability
  # Ensures minimum number of processor pods remain available during voluntary disruptions
  podDisruptionBudget:
    enabled: false
    minAvailable: 1

  # Priority class for pod scheduling priority
  # Higher priority pods are scheduled before lower priority pods
  # Use "system-cluster-critical" or "system-node-critical" for critical workloads
  priorityClassName: ""

# ============================================================================
# Advanced Configuration
# ============================================================================

# TLS/SSL Configuration
tls:
  enabled: false
  # Paths to certificate and key files (mounted via secrets)
  certPath: "/etc/influxdb/tls/tls.crt"
  keyPath: "/etc/influxdb/tls/tls.key"
  minVersion: "tls-1.2"             # tls-1.2 or tls-1.3
  # Existing secret containing TLS cert/key
  # Secret should contain keys: tls.crt, tls.key
  existingSecret: ""

# Authentication configuration
auth:
  # Disable authentication (dev/testing only - NOT RECOMMENDED)
  enabled: true
  # Disable authorization for specific endpoints
  # Default: ["health"] - allows Kubernetes probes without authentication
  # Available endpoints: health, ping, metrics
  # Set to [] to require authentication for all endpoints
  disableAuthz: ["health"]
  # Offline token files (for automated deployments)
  adminTokenFile: ""
  permissionTokensFile: ""

# HTTP server configuration
http:
  bind: "0.0.0.0:8181"
  maxRequestSize: 10485760          # 10MB default

# Write-Ahead Log (WAL) configuration
wal:
  flushInterval: "1s"               # How often to flush WAL
  snapshotSize: 600                 # WAL files per snapshot
  maxWriteBufferSize: 100000        # Max buffered writes before flush
  snapshotFilesToKeep: 300          # Snapshotted WAL files to retain
  replayFailOnError: false
  replayConcurrencyLimit: null      # null = auto (max(num_cpus, 10))

# Caching configuration
cache:
  # Parquet file caching
  parquetMemCacheSize: "20%"        # Or absolute like "4096" (MB)
  parquetMemCacheQueryPathDuration: "5h"
  parquetMemCachePrunePercentage: 0.1
  parquetMemCachePruneInterval: "1s"
  disableParquetMemCache: false
  preemptiveCacheAge: "3d"

  # Last value cache
  lastValueCacheDisableFromHistory: false
  lastCacheEvictionInterval: "10s"

  # Distinct value cache
  distinctValueCacheDisableFromHistory: false
  distinctCacheEvictionInterval: "10s"

  # Table index cache
  tableIndexCacheMaxEntries: 1000
  tableIndexCacheConcurrencyLimit: 8

# Resource limits
limits:
  numDatabases: 100                 # Max databases
  numTables: 10000                  # Max tables across all databases
  numColumnsPerTable: 500           # Max columns per table
  queryFileLimit: null              # Limit Parquet files per query (null = unlimited)

# Data lifecycle management
dataLifecycle:
  gen1LookbackDuration: "24h"       # Lookback for gen1 Parquet files
  retentionCheckInterval: "30m"     # How often to check retention policies
  deleteGracePeriod: "24h"          # Grace period before permanent deletion
  hardDeleteDefaultDuration: "90d"  # Default hard delete duration

# Logging configuration
logging:
  filter: "info"                    # trace, debug, info, warn, error
  destination: "stdout"             # stdout or stderr
  format: "full"
  queryLogSize: 1000                # Query log size

# Tracing configuration (optional)
tracing:
  enabled: false
  exporter: "jaeger"                # jaeger or none
  jaeger:
    agentHost: "jaeger-agent"
    agentPort: 6831
    serviceName: "influxdb3-enterprise"
    traceContextHeaderName: "uber-trace-id"
    debugName: "jaeger-debug-id"
    tags: ""
    maxMsgsPerSecond: 1000

# DataFusion advanced configuration
datafusion:
  maxParquetFanout: 1000
  useCachedParquetLoader: false
  config: ""                        # Custom key:value pairs

# Telemetry
telemetry:
  disableUpload: false              # Set true to opt-out of InfluxData telemetry
  endpoint: ""                      # Custom telemetry endpoint

# ============================================================================
# Ingress Configuration
# ============================================================================
# Separate ingresses for write and query traffic

ingress:
  # Ingress for write traffic (to ingesters)
  # Routes: /api/v3/write_lp, /api/v2/write, /write → Ingester
  write:
    enabled: true
    className: "nginx"
    annotations:
      nginx.ingress.kubernetes.io/proxy-body-size: "100m"
      nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    hosts:
      - host: ""
        paths:
          - path: /api/v3/write_lp
            pathType: Prefix
          - path: /api/v2/write
            pathType: Prefix
          - path: /write
            pathType: Prefix
    tls: []

  # Ingress for query traffic (to queriers)
  # Routes: /api/v3/query*, /query, / (default) → Querier
  query:
    enabled: true
    className: "nginx"
    annotations:
      nginx.ingress.kubernetes.io/proxy-read-timeout: "600"
    hosts:
      - host: ""
        paths:
          - path: /api/v3/query
            pathType: Prefix
          - path: /query
            pathType: Prefix
          - path: /
            pathType: Prefix
    tls: []

  # Ingress for HTTP-triggered plugins (optional, only if processingEngine.enabled)
  processor:
    enabled: false
    className: "nginx"
    annotations: {}
    hosts:
      - host: processor.influxdb.example.com
        paths:
          - path: /api/v3/engine
            pathType: Prefix
    tls: []

# ============================================================================
# Network Policies (optional, disabled by default)
# ============================================================================
# Secure communication between components
#
# To enable network policies, set networkPolicy.enabled: true
# NOTE: Requires a CNI plugin that supports NetworkPolicy (e.g., Calico, Cilium)

networkPolicy:
  enabled: false
  # Policy type
  policyTypes:
    - Ingress
    - Egress

  # Ingress rules
  ingress:
    # Allow ingress controller to reach ingesters and queriers
    fromIngressController: true
    # Ingress controller configuration (cluster-specific)
    ingressController:
      # Namespace where ingress controller runs
      namespace: ingress-nginx
      # Namespace label selector (use kubernetes.io/metadata.name for standard k8s namespaces)
      namespaceLabel: kubernetes.io/metadata.name
      # Pod label selector for ingress controller pods
      podLabelKey: app.kubernetes.io/name
      podLabelValue: ingress-nginx
      # Common alternatives:
      #   NGINX Ingress: app.kubernetes.io/name: ingress-nginx (default)
      #   Traefik: app.kubernetes.io/name: traefik
      #   HAProxy: app.kubernetes.io/name: haproxy-ingress
    # Allow inter-component communication
    fromComponents: true
    # Allow Prometheus to scrape metrics (for cross-namespace monitoring)
    fromPrometheus: false
    # Prometheus configuration (cluster-specific)
    prometheus:
      # Namespace where Prometheus runs
      namespace: monitoring
      # Namespace label selector (use kubernetes.io/metadata.name for standard k8s namespaces)
      namespaceLabel: kubernetes.io/metadata.name
      # Pod label selector for Prometheus pods
      podLabelKey: app.kubernetes.io/name
      podLabelValue: prometheus
      # Common alternatives:
      #   Prometheus Operator: app.kubernetes.io/name: prometheus
      #   kube-prometheus-stack: app: prometheus
      #   Custom: app: my-prometheus

  # Egress rules
  egress:
    # Allow DNS resolution
    toDns: true
    # DNS configuration (cluster-specific)
    dns:
      # Namespace where DNS service runs
      namespace: kube-system
      # Namespace label selector (use kubernetes.io/metadata.name for standard k8s namespaces)
      namespaceLabel: kubernetes.io/metadata.name
      # Pod label selector for DNS pods
      podLabelKey: k8s-app
      podLabelValue: kube-dns
      # Common alternatives:
      #   CoreDNS: k8s-app: kube-dns (default in most clusters)
      #   kube-dns: k8s-app: kube-dns
      #   Custom: app: coredns

    # Allow access to object storage
    toObjectStorage: true
    # Optional: Specify CIDR blocks for object storage endpoints (recommended for production)
    # If not set, allows egress to any destination on ports 443/80/9000 (permissive)
    # Examples:
    #   AWS S3 (us-east-1): 52.216.0.0/15, 54.231.0.0/16
    #   Azure Storage: Varies by region, see https://www.microsoft.com/en-us/download/details.aspx?id=56519
    #   GCS: 142.250.0.0/15, 172.217.0.0/16
    #   MinIO in-cluster: Use namespace/pod selectors instead
    objectStorageCidrs: []
    # - "52.216.0.0/15"
    # - "54.231.0.0/16"

    # Allow outbound HTTP/HTTPS for plugin operations (processor only)
    # Enables plugins to call external webhooks, APIs, notification services, etc.
    toPluginEndpoints: true
    # Optional: Specify CIDR blocks for plugin endpoints (recommended for production)
    # If not set, allows egress to any destination on ports 443/80 (permissive)
    pluginEndpointCidrs: []
    # - "192.0.2.0/24"

# ============================================================================
# Monitoring (optional, disabled by default)
# ============================================================================

serviceMonitor:
  enabled: false
  # Namespace where ServiceMonitor will be created (defaults to release namespace)
  namespace: ""
  # Scrape interval
  interval: 30s
  # Scrape timeout
  scrapeTimeout: 10s
  # Additional labels for ServiceMonitor (for Prometheus operator selector)
  additionalLabels: {}
  # prometheus: kube-prometheus

# ============================================================================
# Service Account
# ============================================================================

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

# ============================================================================
# Additional Configuration
# ============================================================================

# Extra environment variables for all pods
extraEnv: []
  # - name: CUSTOM_VAR
#   value: "custom-value"

# Extra volumes for all pods
extraVolumes: []
  # - name: custom-config
  #   configMap:
#     name: custom-config

# Extra volume mounts for all pods
extraVolumeMounts: []
  # - name: custom-config
#   mountPath: /etc/custom
